{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10c55326",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## What are gates?\n",
    "As players progress through the game, they will occasionally encounter gates that force them to wait for some time or make an in-app purchase to progress. \n",
    "\n",
    "## What is the purpose of the gate?\n",
    "The main objective of these gates is to drive in-app sales, but they are also useful to invite users to make a pause from playing the game (suuuure).\n",
    "\n",
    "## What is the purpose of the experiment?\n",
    "\n",
    "The purpose of the experiment is to test the effect of moving the first gate in Cookie Cats from level 30 to level 40 on player retention.\n",
    "\n",
    "## What is the null hypothesis?\n",
    "\n",
    "The null hypothesis is that moving the first gate in Cookie Cats from level 30 to level 40 has no effect on player retention.\n",
    "\n",
    "\n",
    "\n",
    "## What are the target metrics?\n",
    "\n",
    "The target metrics are retention_1 and retention_7. These metrics are binary, where 1 means that the player came back to play the game after 1 or 7 days and 0 means that the player did not come back to play the game after 1 or 7 days."
   ]
  },
  {
   "cell_type": "code",
   "id": "7df11b5c",
   "metadata": {},
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "path = kagglehub.dataset_download(\"mursideyarkin/mobile-games-ab-testing-cookie-cats\")\n",
    "df = pd.read_csv(path + \"/cookie_cats.csv\")\n",
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a8d07010001c56a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## What are the fields from the dataset?\n",
    "\n",
    "* *userid*: A unique number that identifies each player.\n",
    "* *version*: Whether the player was put in the control group (gate_30 - a gate at level 30) or the group with the moved gate (gate_40 - a gate at level 40).\n",
    "* *sum_gamerounds*: the number of game rounds played by the player during the first 14 days after install.\n",
    "* *retention_1*: Did the player come back and play 1 day after installing?\n",
    "* *retention_7*: Did the player come back and play 7 days after installing?"
   ],
   "id": "89c793b561abc092"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## What are the target metrics?\n",
    "\n",
    "The target metrics are retention_1 and retention_7. These metrics are binary, where 1 means that the player came back to play the game after 1 or 7 days and 0 means that the player did not come back to play the game after 1 or 7 days."
   ],
   "id": "de16f30a9d633e73"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## What is the sample size?",
   "id": "1363f843284067c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.shape[0]",
   "id": "23f2ea2bf83c159a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The sample size is 90,189 players who installed the game while the AB-test was running.",
   "id": "82b0a85f51d5a71b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## What is the test group size?",
   "id": "5cd1d32e49cc14b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.groupby(\"version\").size()",
   "id": "321bd264443e2061",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We have 44,495 players in the gate_30 group and 45,694 players in the gate_40 group. We can see that the test group is well-balanced.",
   "id": "4e4886fe17030f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## What are the variant proportions?",
   "id": "483c38e8b7aaa4d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.groupby(\"version\").size() / df.shape[0]",
   "id": "e2ae7e03dc51f53e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The variant proportions are 0.493 and 0.507. The proportions are well-balanced. It's a characteristic of a good sample size.",
   "id": "5020502315d25f11"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Statistical Tests",
   "id": "b602d8b70e7098cd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Looking at the data, there are a couple of way to test the hypothesis:\n",
    "\n",
    "For metrics like `retention_1` and `retention_7`:\n",
    "* Chi-square test to check for Sample Ratio Mismatch and then use the Chi-square test to analyze the binary metric.\n",
    "* Binomial test to check the difference between the two proportions, but specifically how the difference compares to baseline. # TODO: What is baseline in our case?"
   ],
   "id": "e0b342824fb95494"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a figure with both histogram and box plot using subplots\n",
    "fig = px.histogram(df, x='sum_gamerounds',\n",
    "                   title='Distribution of Game Rounds',\n",
    "                   labels={'sum_gamerounds': 'Number of Game Rounds'},\n",
    "                   color='version',\n",
    "                   marginal='box',  # This adds a box plot above\n",
    "                   hover_data=['version'])\n",
    "\n",
    "# Update layout for better readability\n",
    "fig.update_layout(\n",
    "    title_x=0.5,  # Center the title\n",
    "    bargap=0.1,  # Add space between bars\n",
    "    height=600,  # Make plot taller for better visibility\n",
    "    xaxis_title=\"Number of Game Rounds\",\n",
    "    yaxis_title=\"Count of Players\"\n",
    ")\n",
    "\n",
    "# If you want to zoom in to see the main distribution better\n",
    "# (since there might be extreme outliers), we can set the x-axis range\n",
    "# Let's show up to the 95th percentile\n",
    "x_limit = np.percentile(df['sum_gamerounds'], 95)\n",
    "fig.update_xaxes(range=[0, x_limit])\n",
    "\n",
    "fig.show()"
   ],
   "id": "27997289235ff53e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* We can see the distribution is heavily right-skewed\n",
    "    * Most players complete relatively few game rounds\n",
    "    * Some players complete many game rounds\n",
    "    * This is very far from a normal distribution (bell curve)\n",
    "\n",
    "* The boxes (representing the middle 50% of players) are quite compressed near the left\n",
    ". The whiskers (the lines extending from the boxes) are very long to the right\n",
    "There are many dots beyond the whiskers, representing outliers.\n",
    "     * Both gate_30 (blue) and gate_40 (red) show similar patterns\n",
    "     * The distributions largely overlap\n",
    "     * Both versions have similar shapes and outlier patterns\n",
    "          *\n",
    "\n",
    "Given these observations, we should definitely use the [Mann-Whitney U](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html#scipy.stats.mannwhitneyu) test instead of a t-test because:\n",
    "\n",
    "* The data is not normally distributed # TODO: what is non-normal? Bell-curve?\n",
    "* We have many outliers\n",
    "* The variances between groups appear unequal # TODO: What is variance\n",
    "\n",
    "The Mann-Whitney U test will be more reliable because it:\n",
    "\n",
    "* Doesn't assume normality\n",
    "* Works with skewed distributions\n",
    "* Is less sensitive to outliers\n",
    "* Compares ranks rather than raw values"
   ],
   "id": "13e369672b07188"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy import stats\n",
    "\n",
    "# 1. Split the data into two groups\n",
    "gate_30_rounds = df[df['version'] == 'gate_30']['sum_gamerounds']\n",
    "gate_40_rounds = df[df['version'] == 'gate_40']['sum_gamerounds']\n",
    "\n",
    "# 2. Perform Mann-Whitney U test\n",
    "statistic, p_value = stats.mannwhitneyu(\n",
    "    gate_30_rounds,\n",
    "    gate_40_rounds,\n",
    "    alternative='two-sided'  # Test if there's any difference between groups (not just one being larger)\n",
    ")\n",
    "\n",
    "# 3. Calculate some descriptive statistics to help interpret results\n",
    "stats_summary = {\n",
    "    'gate_30': {\n",
    "        'median': gate_30_rounds.median(),\n",
    "        'mean': gate_30_rounds.mean(),\n",
    "        'count': len(gate_30_rounds)\n",
    "    },\n",
    "    'gate_40': {\n",
    "        'median': gate_40_rounds.median(),\n",
    "        'mean': gate_40_rounds.mean(),\n",
    "        'count': len(gate_40_rounds)\n",
    "    }\n",
    "}\n",
    "\n",
    "# 4. Print results in a clear format\n",
    "print(\"Mann-Whitney U Test Results:\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"\\nDescriptive Statistics:\")\n",
    "for version, stats_dict in stats_summary.items():\n",
    "    print(f\"\\n{version}:\")\n",
    "    print(f\"  Median rounds: {stats_dict['median']:.2f}\")\n",
    "    print(f\"  Mean rounds: {stats_dict['mean']:.2f}\")\n",
    "    print(f\"  Sample size: {stats_dict['count']}\")\n",
    "\n",
    "# 5. Print conclusion\n",
    "alpha = 0.05  # Standard significance level\n",
    "print(f\"\\nConclusion:\")\n",
    "if p_value < alpha:\n",
    "    print(f\"There is a statistically significant difference between the groups (p < {alpha})\")\n",
    "else:\n",
    "    print(f\"There is no statistically significant difference between the groups (p > {alpha})\")"
   ],
   "id": "d6879a8451d8ec77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Test Significance (p-value = 0.0502):\n",
    "\n",
    "This is just barely above our standard significance level of 0.05\n",
    "It's very close to being significant, but technically isn't\n",
    "This kind of \"borderline\" result warrants careful interpretation\n",
    "\n",
    "Group Comparisons:\n",
    "\n",
    "Gate 30:\n",
    "\n",
    "Median: 17 rounds\n",
    "Mean: 52.46 rounds\n",
    "Sample size: 44,700 players\n",
    "\n",
    "Gate 40:\n",
    "\n",
    "Median: 16 rounds\n",
    "Mean: 51.30 rounds\n",
    "Sample size: 45,489 players\n",
    "\n",
    "Key Insights:\n",
    "\n",
    "The difference is very small in practical terms\n",
    "Mean values are much higher than medians (confirms our earlier observation about skewed distribution)\n",
    "Sample sizes are very large and almost equal between groups\n",
    "\n",
    "Business Interpretation:\n",
    "\n",
    "Players in Gate 30 play slightly more rounds on average (about 1 round more)\n",
    "The difference is not statistically significant, **but might be practically meaningful given the large sample size**. Here we would have to consult to domain experts.\n",
    "Given that Gate 30 shows slightly better numbers and is an easier level, it might be the safer choice"
   ],
   "id": "ebf8c4ddbf3a40f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
